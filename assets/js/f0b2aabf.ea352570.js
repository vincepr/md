"use strict";(self.webpackChunkmd=self.webpackChunkmd||[]).push([[7434],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>h});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},s=Object.keys(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)n=s[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=r.createContext({}),p=function(e){var t=r.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},m=function(e){var t=p(e.components);return r.createElement(i.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,s=e.originalType,i=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=p(n),d=a,h=c["".concat(i,".").concat(d)]||c[d]||u[d]||s;return n?r.createElement(h,l(l({ref:t},m),{},{components:n})):r.createElement(h,l({ref:t},m))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var s=n.length,l=new Array(s);l[0]=d;var o={};for(var i in t)hasOwnProperty.call(t,i)&&(o[i]=t[i]);o.originalType=e,o[c]="string"==typeof e?e:a,l[1]=o;for(var p=2;p<s;p++)l[p]=n[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},9546:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>s,metadata:()=>o,toc:()=>p});var r=n(7462),a=(n(7294),n(3905));const s={},l="part6 - Sql inside Kubernetes",o={unversionedId:"csharp/examples/Microservices/part6-sqlKubernetes",id:"csharp/examples/Microservices/part6-sqlKubernetes",title:"part6 - Sql inside Kubernetes",description:"- creating Sql Server inside Kubernetes",source:"@site/docs/csharp/examples/Microservices/part6-sqlKubernetes.md",sourceDirName:"csharp/examples/Microservices",slug:"/csharp/examples/Microservices/part6-sqlKubernetes",permalink:"/md/csharp/examples/Microservices/part6-sqlKubernetes",draft:!1,editUrl:"https://github.com/vincepr/md/blob/main/docs/csharp/examples/Microservices/part6-sqlKubernetes.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"part5 - NGINX Api-Gateway",permalink:"/md/csharp/examples/Microservices/part5-NGINX-Gateway"},next:{title:"part 7 - multi resource api",permalink:"/md/csharp/examples/Microservices/part7-multiResourceApi"}},i={},p=[{value:"Terminology",id:"terminology",level:2},{value:"create the persistent volume claim",id:"create-the-persistent-volume-claim",level:2},{value:"use kubernetes secrets to store the sensitive data (here sql-password)",id:"use-kubernetes-secrets-to-store-the-sensitive-data-here-sql-password",level:2},{value:"create the ms-sql-server deploy",id:"create-the-ms-sql-server-deploy",level:2},{value:"Generate the Migrations:",id:"generate-the-migrations",level:3},{value:"Solution A",id:"solution-a",level:3},{value:"Solution B",id:"solution-b",level:3},{value:"building, pushing to dockerhub, applying and restarting the kubernetesService",id:"building-pushing-to-dockerhub-applying-and-restarting-the-kubernetesservice",level:3}],m={toc:p};function c(e){let{components:t,...s}=e;return(0,a.kt)("wrapper",(0,r.Z)({},m,s,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"part6---sql-inside-kubernetes"},"part6 - Sql inside Kubernetes"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"creating Sql Server inside Kubernetes")),(0,a.kt)("h2",{id:"terminology"},"Terminology"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Persistent Volume Claim - we stake in our yaml file that we need some persistent storage"),(0,a.kt)("li",{parentName:"ol"},"Persistent Volume - this gets created under the hood. Ex Docker volume"),(0,a.kt)("li",{parentName:"ol"},"Storage Class - our local filesystem")),(0,a.kt)("p",null,"Since were using just a local machine, we only need to set up the first step. In AWS etc. every part would need to be configured."),(0,a.kt)("h2",{id:"create-the-persistent-volume-claim"},"create the persistent volume claim"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"local-volumeclaim.yaml")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"# the persistent volume claim. Basically to stake out real memory for the SQl-DB\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mssql-claim\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 200Mi\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"next create our claim: (",(0,a.kt)("inlineCode",{parentName:"li"},"hosepath")," is the default filesystem that shows up ",(0,a.kt)("inlineCode",{parentName:"li"},"kubectl get storageclass"),")")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"kubectl apply -f K8S/local-volumeclaim.yaml\n\nkubectl get pvc\n# NAME          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n# mssql-claim   Bound    pvc-263b1ab8-3f24-498f-b998-8aeea72f022b   200Mi      RWX            hostpath       57s\n")),(0,a.kt)("h2",{id:"use-kubernetes-secrets-to-store-the-sensitive-data-here-sql-password"},"use kubernetes secrets to store the sensitive data (here sql-password)"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'kubectl create secret generic mssql --from-literal=SA_PASSWORD="pa55sword!"\n')),(0,a.kt)("h2",{id:"create-the-ms-sql-server-deploy"},"create the ms-sql-server deploy"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"mssql-plat-depl.yaml"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mssql-depl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mssql\n  template:\n    metadata:\n      labels:\n        app: mssql\n    spec:\n      containers:\n        - name: mssql\n          image: mcr.microsoft.com/mssql/server:2017-latest\n          ports:\n            - containerPort: 1443\n          env:\n            - name: MSSQL_PID\n              value: "Express"\n            - name: ACCEPT_EULA\n              value: "Y"\n            - name: SA_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: mssql ## this name came from the `kubectl create secret generic mssql --from-literal=SA_PASSWORD="password123!"`\n                  key: SA_PASSWORD\n          volumeMounts:\n            ## the path where in our dockercontainer the data is located at:\n            - mountPath: /var/opt/mssql/data\n              name: mssqldb\n      volumes:\n        - name: mssqldb\n          persistentVolumeClaim:\n            ## this references the one we created in our: `local-volumeclaim.yaml` \n            claimName: mssql-claim\n---\n# the DB needs to be accessible for it\'s Service so we create a ClusterIP for it\napiVersion: v1\nkind: Service\nmetadata:\n  name: mssql-clusterip-srv\nspec:\n  type: ClusterIP\n  selector:\n    app: mssql\n  ports:\n    - name: mssql\n      protocol: TCP\n      port: 1433\n      targetPort: 1433\n---\n# the DB also needs to be accessible from outside the Kubernetes (at least for development)\n# so we create a LoadbalancerService for it\napiVersion: v1\nkind: Service\nmetadata:\n  name: mssql-loadbalancer\nspec:\n  type: LoadBalancer\n  selector:\n    app: mssql\n  ports:\n  - protocol: TCP\n    port: 1433\n    targetPort: 1433\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"then we fire it up:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"we can see how it shows up in colum: ",(0,a.kt)("inlineCode",{parentName:"li"},"EXTERNAL-IP=localhost")," so we should be able to reach there at port 1433")))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"kubectl apply -f K8S/mssql-plat-depl.yaml\n\nkubectl get services\n# NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\n# commands-clusterip-srv    ClusterIP      10.105.102.58   <none>        80/TCP           10h\n# kubernetes                ClusterIP      10.96.0.1       <none>        443/TCP          5d1h\n# mssql-clusterip-srv       ClusterIP      10.105.73.193   <none>        1433/TCP         64s\n# mssql-loadbalancer        LoadBalancer   10.103.72.144   localhost     1433:31483/TCP   64s\n# platformnpservice-srv     NodePort       10.103.51.73    <none>        80:30085/TCP     4d1h\n# platforms-clusterip-srv   ClusterIP      10.97.239.139   <none>        80/TCP           10h\n")),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Alt text",src:n(1460).Z,width:"889",height:"632"})),(0,a.kt)("h1",{id:"part52"},"part5/2"),(0,a.kt)("p",null,"We want to use the sql-db inside the Kubernetes Cluster. While keeping the in-memory-db in the normal development environment (",(0,a.kt)("inlineCode",{parentName:"p"},"dotnet run"),")"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"appesettings.Production.json")," we add the ConnectionString")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "CommandService": "http://commands-clusterip-srv:80/api/c/platforms/",\n    "ConnectionStrings" : {\n        "PlatformsConn" : "Server=mssql-clusterip-srv,1433;Initial Catalog=platformsdb;User ID=sa;Password=pa55sword!;"\n    }\n}\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"we switch from using the in memory db all the time in ",(0,a.kt)("inlineCode",{parentName:"li"},"Program.cs"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-csharp"},'// we inject our Database context\nbuilder.Services.AddDbContext<AppDbContext>(opts => {\n    opts.UseInMemoryDatabase("InMem");\n});\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"to switchting db implementation depending on prod/dev:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-csharp"},'// we inject our Database context\nbuilder.Services.AddDbContext<AppDbContext>(opts => {\n    if (builder.Environment.IsProduction()) {\n        Console.WriteLine("--\x3e CASE PRODUCTION - using SqlServerDb");\n        opts.UseSqlServer(builder.Configuration.GetConnectionString("PlatformsConn"));\n    } else {\n        Console.WriteLine("--\x3e CASE DEV - using InMemoryDB");\n        opts.UseInMemoryDatabase("InMem");\n    }\n});\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"the in memory db doesnt need/want any Migrations. But when running against the real DB we want to apply those. In our ",(0,a.kt)("inlineCode",{parentName:"li"},"Data/PrepDb.cs")," we add:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-csharp"},'// we want to migrate our migrations when against the real DB:\nif(isProduction) {\n    Console.WriteLine("--\x3e Attempting to apply migrations.. ");\n    try {\n        ctx.Database.Migrate();\n    } catch(Exception e) {\n        Console.WriteLine($"--\x3e Failed to run migrations! {e.Message}");\n    }\n}\n')),(0,a.kt)("h3",{id:"generate-the-migrations"},"Generate the Migrations:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"THE FOLLOWING WILL NOT WORK:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"!! dotnet --project PlatformService ef migrations add initialMigration\n\n>>\nUnable to resolve service for type 'Microsoft.EntityFrameworkCore.Migrations.IMigrator'. This is often because no database provider has been configured for this DbContext. A provider can be configured by overriding the 'DbContext.OnConfiguring' method or by using 'AddDbContext' on the application service provider. If 'AddDbContext' is used, then also ensure that your DbContext type accepts a DbContextOptions<TContext> object in its constructor and passes it to the base constructor for DbContext.    \n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"this happens because EntityFrameworks needs a NON-InMemoryDB provider to build its Migrations for.")),(0,a.kt)("h3",{id:"solution-a"},"Solution A"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"So we want to trick EF to think were using SQL server at. We could temporary comment out like this:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-csharp"},'// if (builder.Environment.IsProduction()) {\n    Console.WriteLine("--\x3e CASE PRODUCTION - using SqlServerDb");\n    opts.UseSqlServer(builder.Configuration.GetConnectionString("PlatformsConn"));\n// } else {\n//     Console.WriteLine("--\x3e CASE DEV - using InMemoryDB");\n//     opts.UseInMemoryDatabase("InMem");\n// }\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"and then revert back once we ran the ",(0,a.kt)("inlineCode",{parentName:"li"},"dotnet --project PlatformService ef migrations add initialMigration"))),(0,a.kt)("h3",{id:"solution-b"},"Solution B"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The for me cleaner looking way. Passing the environment to dotnet in the terminal:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"so it will build migrations assuming env.Development is set.")))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"dotnet ef --project PlatformService migrations add initialMigration -- --environment Production\n")),(0,a.kt)("h3",{id:"building-pushing-to-dockerhub-applying-and-restarting-the-kubernetesservice"},"building, pushing to dockerhub, applying and restarting the kubernetesService"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"docker build -t vincepr/platformservice ./PlatformService\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"2023-10-15 12:49:07 --\x3e CASE PRODUCTION - using SqlServerDb\n2023-10-15 12:49:07 --\x3e Attempting to apply migrations.. \n2023-10-15 12:49:08 info: Microsoft.EntityFrameworkCore.Database.Command[20101]\n2023-10-15 12:49:08       Executed DbCommand (616ms) [Parameters=[], CommandType='Text', CommandTimeout='60']\n2023-10-15 12:49:08       CREATE DATABASE [platformsdb];\n// ..\n23-10-15 12:49:09       Executed DbCommand (7ms) [Parameters=[], CommandType='Text', CommandTimeout='30']\n2023-10-15 12:49:09       CREATE TABLE [Platforms] (\n2023-10-15 12:49:09           [Id] int NOT NULL IDENTITY,\n2023-10-15 12:49:09           [Name] nvarchar(max) NOT NULL,\n2023-10-15 12:49:09           [Publisher] nvarchar(max) NOT NULL,\n2023-10-15 12:49:09           [Cost] nvarchar(max) NOT NULL,\n2023-10-15 12:49:09           CONSTRAINT [PK_Platforms] PRIMARY KEY ([Id])\n2023-10-15 12:49:09       );\n\n// ...\n\n2023-10-15 12:49:09 --\x3e Seeding Data with some made up Data\n// ...\n2023-10-15 12:49:09       INSERT ([Cost], [Name], [Publisher])\n2023-10-15 12:49:09       VALUES (i.[Cost], i.[Name], i.[Publisher])\n2023-10-15 12:49:09       OUTPUT INSERTED.[Id], i._Position;\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"we can now check into our persistent db and the 3 seed-Platforms should show up:\n",(0,a.kt)("img",{alt:"Alt text",src:n(6832).Z,width:"1164",height:"689"}))))}c.isMDXComponent=!0},1460:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/sqlLogin-7a3d90f63ad1761fb89641306ab750f6.png"},6832:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/sqlTestQuery-7de6366d93a9cb060a82593387bb12da.png"}}]);