"use strict";(self.webpackChunkmd=self.webpackChunkmd||[]).push([[133],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>d});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),u=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},c=function(e){var n=u(e.components);return a.createElement(s.Provider,{value:n},e.children)},h="mdxType",y={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),h=u(t),p=r,d=h["".concat(s,".").concat(p)]||h[p]||y[p]||i;return t?a.createElement(d,l(l({ref:n},c),{},{components:t})):a.createElement(d,l({ref:n},c))}));function d(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,l=new Array(i);l[0]=p;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o[h]="string"==typeof e?e:r,l[1]=o;for(var u=2;u<i;u++)l[u]=t[u];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},650:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>u});var a=t(7462),r=(t(7294),t(3905));const i={},l="Hash Table - Hash Map",o={unversionedId:"datastructures/hashtable",id:"datastructures/hashtable",title:"Hash Table - Hash Map",description:"- aka HashMaps, Maps, Dictionaries etc. Key-Value pairs.",source:"@site/docs/datastructures/hashtable.md",sourceDirName:"datastructures",slug:"/datastructures/hashtable",permalink:"/md/datastructures/hashtable",draft:!1,editUrl:"https://github.com/vincepr/md/blob/main/docs/datastructures/hashtable.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Basic structures",permalink:"/md/datastructures/dynamic_array"},next:{title:"Linked List (Singly Linked List)",permalink:"/md/datastructures/linked_list"}},s={},u=[{value:"Strategies to handle collisions.",id:"strategies-to-handle-collisions",level:2},{value:"Separate Chaining",id:"separate-chaining",level:3},{value:"Advantages",id:"advantages",level:4},{value:"Disadvantages",id:"disadvantages",level:4},{value:"Performance",id:"performance",level:4},{value:"Implementation in C - Open Adressing",id:"implementation-in-c---open-adressing",level:2},{value:"table.h",id:"tableh",level:3},{value:"table.c",id:"tablec",level:3},{value:"Separate Chaining Hash Table in Csharp",id:"separate-chaining-hash-table-in-csharp",level:2}],c={toc:u};function h(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"hash-table---hash-map"},"Hash Table - Hash Map"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"aka HashMaps, Maps, Dictionaries etc. Key-Value pairs."),(0,r.kt)("li",{parentName:"ul"},"use key (often a string) to lookup the corresponding Value.")),(0,r.kt)("h2",{id:"strategies-to-handle-collisions"},"Strategies to handle collisions."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Collisions are unavoidable and get more likely the higher the load-factor (aka the fuller the list / it's capacity)"),(0,r.kt)("li",{parentName:"ul"},"Different Strategies deal with how to handle those collisions:")),(0,r.kt)("h3",{id:"separate-chaining"},"Separate Chaining"),(0,r.kt)("p",null,"Combines a linked list with the HashTable."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Can be extended to use Dynamic-Sized-Arrays or Self-Balancing-Trees instead of simple linked-list.")),(0,r.kt)("p",null,"All elements that hash into the same slot index are inserted into a lined list. (ex. a .Next Attribuzte for each Entry) "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"then we can just traverse that linked list to find our Key. If we reach the end before we find it, we know its not jet in the table.")),(0,r.kt)("h4",{id:"advantages"},"Advantages"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Simple to implement"),(0,r.kt)("li",{parentName:"ul"},"Less sensitive to hash function or load factors. (since linked list does a bunch)"),(0,r.kt)("li",{parentName:"ul"},"hash table doesnt need to be re-allocated since we can always just add more elements to the chain.")),(0,r.kt)("h4",{id:"disadvantages"},"Disadvantages"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"bad cache performance. Chaining is bad since not consecutive in memory. (ex. open adressing provides better chache performance)"),(0,r.kt)("li",{parentName:"ul"},"long chains near O(n) lookup in the worst case"),(0,r.kt)("li",{parentName:"ul"},"Wastage of Memory. Extra space for references. Some Parts of the table never fill up.")),(0,r.kt)("h4",{id:"performance"},"Performance"),(0,r.kt)("h2",{id:"implementation-in-c---open-adressing"},"Implementation in C - Open Adressing"),(0,r.kt)("p",null,"For the full implementation (with context( check out ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/vincepr/c_compiler/blob/main/src/table.h"},"https://github.com/vincepr/c_compiler/blob/main/src/table.h")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"that version also uses special lookups with string interning to get even more lookup speed.")),(0,r.kt)("h3",{id:"tableh"},"table.h"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-c"},"#ifndef clox_table_h\n#define clox_table_h\n\n/*\n    Hash Map implementation\n    - Thought: We allow variables up to eight characters long (or just hash on those first 8chars)\n    - We get 26 unique chars ('a'-'Z' + '0'-'9' +'_'). We can squash all that info in a 64bit int\n    - (if we map that to a continous block we would need 295148PetaByte) so we take the value modulo of the size of the array\n        this folds the larger numeric range onto itself untill it fits in a smaller range of array elements\n    - because of the above we have to handle hash-collisions though.\n        - to mimiize the chance of collisions, we can dynamically calculate the load-factor (entry_number/bucket_number).\n            if the load factor gets to big we resize and grow the array bigger\n    - to avoid the 8char limit we use a deterministic/uniform/fast hash function.\n        - clox implements the FNV-1a Hashing-Function   http://www.isthe.com/chongo/tech/comp/fnv/\n*/\n\n/*\n    Techniques for resolving collisions: 2 basic Techniques: \n    \n    SEPARATE CHAINING (not used for this):\n    - each bucket containts more than one entries. For example a linked list of entries.\n        To lookup an entry you just walk the linked list till you found the fitting entry\n    - worst case: would be all data collides on the same bucket -> is basically one linked list\n    - conceptually simple with operation implementations simple. BUT not a great fit for modern CPUs.\n        Because of a lot of overhead from pointers and linked lists are scattered arround memory.\n    \n    OPEN ADRESSING (aka CLOSED HASHING)\n    - all entries live directly in the bucket array.\n    - if two entries collide in the same bucket, we find a different empty bucket to use instead.\n    - the process of finding a free/available bucket is called PROBING. \n    - The Order buckets get examined is a PROBE SEQUENCE. We use a simple variant: \n        - LINEAR PROBING: IF the bucket is full we just go to the next entry and try that, then the next ...\n    - Good: since it tends to cluster data its cache friendly.\n*/\n\n/*\n    For notes on Tombstone strategy used, check comments for tableDelete()\n*/\n\n// The Objects our Maps Holds (ex: key:varname1, value:10.5 )\ntypedef struct {\n    ObjString* key;\n    Value value;\n} Entry;\n\n// The struct of our HashMap\ntypedef struct {\n    int count;          // currently stores key-value pairs\n    int capacity;       // capacity (so can easly get the load-factor: count/capacity)\n    Entry* entries;     // array of the entries we hash\n} Table;\n\nvoid initTable(Table* table);\nvoid freeTable(Table* table);\nbool tableGet(Table* table, ObjString* key, Value* value);\nbool tableSet(Table* table, ObjString* key, Value value);\nbool tableDelete(Table* table, ObjString* key);\nvoid tableAddAll(Table* from, Table* to);\nObjString* tableFindString(Table* table, const char* chars, int length, uint32_t hash);\nvoid tableRemoveWhite(Table* table);\nvoid markTable(Table* table);\n\n/*CUSTOM:*/\nbool tableFindValue(Table* table, const char* chars, int length, uint32_t hash, Value* value);\n\n\n#endif\n")),(0,r.kt)("h3",{id:"tablec"},"table.c"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-c"},"// if our load-factor (=entry_number/bucket_number) reaches this treshold we grow the HashMap size (reallocate it to be 2 times the size)\n#define TABLE_MAX_LOAD 0.75\n\n// constructor for the HashMap\nvoid initTable(Table* table) {\n    table->count = 0;\n    table->capacity = 0;\n    table->entries = NULL;\n}\n\n// basically behaves like a dynamic array (with some extra rules for inserting, delting, searching a value)\nvoid freeTable(Table* table) {\n    FREE_ARRAY(Entry, table->entries, table->capacity);\n    initTable(table);\n}\n\n// HashMap-Functionality - lookup the entry in the Map\n// - for-loop  keeps going bucket by bucket till it finds the key (aka probing)\n// - we exit the loop if we find the key(success) or hit an Empty NULL bucket(notFound)\n// - with a full HashMap the loop WOULD be infinite. BUT since we always grow it at 75% loadfactor this cant happen\n// Tombstone-strategy:\n//  - while probing we keep going on hitting tombstones {key:NULL, value:TRUE}\nstatic Entry* findEntry(Entry* entries, int capacity, ObjString* key) {\n    uint32_t index = key->hash & (capacity - 1);// since we dont have enough memory to map each value directly we fold our scope like this\n    Entry* tombstone = NULL;                    // we store the Tombstones we hit while probing\n\n    for (;;) {\n        Entry* entry = &entries[index];\n        if (entry->key == NULL) {\n            if (IS_NIL(entry->value)) {         //<- empty entry\n                return tombstone != NULL ? tombstone : entry;\n            } else {                            //<- we found a tombstone\n                if (tombstone == NULL) tombstone = entry;\n            }\n        } else if (entry->key == key) {\n            return entry;                       //<- we found the key\n        }\n\n        index = (index + 1) & (capacity -1);    //<- modulo wraps arround if we reach the end of our capacity\n    }\n}\n\n// HashMap-Functionality - If finds entry it returns true, otherwise false. \n// - value-output will point to resulting value if true\nbool tableGet(Table* table, ObjString* key, Value* value) {\n    if (table->count == 0) return false;\n    Entry* entry = findEntry(table->entries, table->capacity, key);\n    if(entry->key == NULL) return false;\n    *value = entry->value;      // set the value-parameter found pointer to value\n    return true;\n}\n\n// grows our HashTable size:\n// we can just write over the memory (because of collisions might become less on bigger space)\n// so we just make a empty new one. Then fill the table entry by entry.\n// - we dont copy Tombstones -> we need to recalculate the entries-count\nstatic void adjustCapacity(Table* table, int capacity){\n    // we allocate an array of (empty) buckets\n    Entry* entries = ALLOCATE(Entry, capacity);\n    for (int i = 0; i<capacity; i++) {\n        entries[i].key = NULL;\n        entries[i].value = NIL_VAL;\n    }\n    table->count = 0;\n\n    // we walk trough the old array front to back. \n    for (int i=0; i<table->capacity; i++) {\n        Entry* entry = &table->entries[i];\n        if (entry->key == NULL) continue;\n        // We insert entries we find to the new array:\n        Entry* dest = findEntry(entries, capacity, entry->key);\n        dest->key = entry->key;\n        dest->value = entry->value;\n        table->count++;\n    }\n    FREE_ARRAY(Entry, table->entries, table->capacity);    // the old table can be free'd\n    // we update the number of entries/capacity for the new array:\n    table->entries = entries;\n    table->capacity = capacity;\n}\n\n// HashMap-Functionality - Add the given key-value-pair to our table:\nbool tableSet(Table* table, ObjString* key, Value value) {\n    // if our load-factor gets to big (to many entries in map) we make the map bigger:\n    if (table->count + 1 > table->capacity * TABLE_MAX_LOAD) {\n        int capacity = GROW_CAPACITY(table->capacity);\n        adjustCapacity(table, capacity);\n    }\n    // figure out what bucket we write to\n    Entry* entry = findEntry(table->entries, table->capacity, key); \n    // then write to that bucket:\n    bool isNewKey = entry->key == NULL; \n    // if key is already present we just overwrote to the same key (updated) -> we dont increment size:\n    // we also check if we write to a NOT Tombstone (the nil-check) only then do we increment\n    if (isNewKey && IS_NIL(entry->value)) table->count++;   \n    entry->key = key;  \n    entry->value = value;\n    return isNewKey;\n}\n\n// HashMap-Functionality - Delete a key-value pair from the Map\n// - the problem is we can just delete the entry directly. Because another entry might have dependet on it's collision when beeing entered\n// - the solution is Tombstones. Instead of clearing the entry on deletion, we replace it with a special entry called tombstone\n//      during probing we dont treat tombstones like empty but keep going (we treat them like full)\nbool tableDelete(Table* table, ObjString* key) {\n    if (table->count == 0) return false;\n    Entry* entry = findEntry(table->entries, table->capacity, key);\n    if (entry->key == NULL) return false;\n\n    // place the tombstone. We use a {key: NULL, Value: true} to represent this.\n    // - this is arbitrarily chosen. Any unique combination (not in use) would work.\n    entry->key = NULL;\n    entry->value = BOOL_VAL(true);\n    return true;\n}\n\n// HashMap-Functionality - Copies all Data from one HashTable to another - ex. used for inheritance (of class-methods)\nvoid tableAddAll(Table* from, Table* to) {\n    for (int i=0; i<from->capacity; i++) {\n        Entry* entry = &from->entries[i];\n        if (entry->key != NULL) {\n            tableSet(to, entry->key, entry->value);\n        }\n    }\n}\n")),(0,r.kt)("h2",{id:"separate-chaining-hash-table-in-csharp"},"Separate Chaining Hash Table in Csharp"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cs"},'\npublic static class Example\n{\n    public static void Run()\n    {\n        Console.WriteLine("--- (Simple) HashTable Example: ---");\n        var table = new ChainingHashTable<int, int>(10)                   // setting starting capactiy =10\n        {\n            {5, 2},\n            {23, 42},\n        };\n\n        for(int i = 10; i < 20; i++)\n            table[i] = i*i*i;\n\n        foreach (var pair in table)\n            Console.WriteLine($"{pair}");\n\n\n        Console.WriteLine("\\n--- --- ---");\n        // everytime the growth factor gets to high it reallocs with double size.\n        Console.WriteLine($"Count: {table.Count} Capacity: {table.Capacity}");\n        Console.WriteLine($"{table.Contains(10)} {table.GetValue(10)}");\n        table.Remove(10);\n        Console.WriteLine($"{table.Contains(10)} {table.GetValue(10)}");\n\n\n        Console.WriteLine("\\n--- --- ---");\n        var table2 = new ChainingHashTable<String, int>(("Bob",24),("James",34),("Gandalf", 5000));\n        table2["Gandalf"] = 55555;\n        table2.Remove("Bob");\n        foreach(var (key, value) in table2)\n            Console.WriteLine($"<{key} {value}>");\n        if (table2.Contains("James"))\n            Console.WriteLine($"James is {table2["James"]}");\n    }\n}\n\n/// <summary>\n/// Implemention of a HashMap using SEPARATE CHAINING with Generic Key-Value pairs.\n/// </summary>\n/// <typeparam name="K">key</typeparam>\n/// <typeparam name="V">value</typeparam>\npublic sealed class ChainingHashTable<K, V>  : IEnumerable<KeyValuePair<K, V>> where K : notnull\n{\n    /// <summary>\n    /// Represents a single key-value pair in our list\n    /// </summary>\n    sealed class Entry\n    {\n        public K Key { get; init; }\n        public V Value { get; set; }\n        public int Hashcode { get; set; }\n        public Entry? Next { get; set; }\n\n        public Entry(K key, V value, int hashcode, Entry? next = null)\n        {\n            this.Key = key;\n            this.Value = value;\n            this.Hashcode = hashcode;\n            this.Next = next;\n        }\n    }\n\n    /* Attributes */\n    private const int START_CAPACITY = 8;\n\n    private Entry?[] entries;\n\n    public int Count { get; private set; }\n\n    /// <summary>\n    /// version, so we can throw if Enumerator changed mid consuming.\n    /// </summary>\n    private int version = 0;                \n    \n    // Number of buckets\n    public int Capacity => entries.Length;        \n\n    public ChainingHashTable(int CAPACITY = START_CAPACITY)\n    {\n        CAPACITY = (CAPACITY > START_CAPACITY) ? CAPACITY : START_CAPACITY;\n        entries = new Entry[CAPACITY];\n    }\n\n    public ChainingHashTable(params (K, V)[] pairs)\n    {\n        int capacity = (pairs.Length*2 > START_CAPACITY) ? pairs.Length*2 : START_CAPACITY;\n        entries = new Entry[capacity];\n        foreach (var pair in pairs)\n            Add(pair.Item1, pair.Item2);\n    }\n\n    /* functionality METHODS */\n    public void Add(K key, V value)\n    {\n        version++;\n        int hashcode = key.GetHashCode();\n        int targetBucket = (hashcode & int.MaxValue) % entries.Length;\n        Entry? targetEntry = entries[targetBucket];\n        \n        // add directly to bucket (first element)\n        if (targetEntry is null)                \n        {\n            entries[targetBucket] = new Entry(key, value, hashcode, null);\n            Count++;\n            ReallocIfNeed();\n            return;\n        }\n        // traverse the linked list:\n        while (targetEntry is not null)\n        {\n            // overwrite existing value\n            if(key.Equals(targetEntry.Key))    \n            {\n                targetEntry.Value = value;\n                return;\n            }\n\n            // add at end of linked list\n            if (targetEntry.Next is null)       \n            {\n                targetEntry.Next = new Entry(key, value, hashcode, null);\n                Count++;\n                ReallocIfNeed();\n                return;\n            }\n            targetEntry = targetEntry.Next;\n        }\n    }\n\n    public bool Contains(K key)\n    {\n        var entry = FindEntry(key);\n        if (entry is null) return false;\n        return true;\n\n    }\n\n    public void Remove(K key)\n    {\n        version++;\n        int hashcode = key.GetHashCode();\n        int targetBucket = (hashcode & int.MaxValue) % entries.Length;\n        Entry? previous = entries[targetBucket];\n        if (previous is null) return;\n        Entry? current = previous.Next;\n        if (current is null) entries[targetBucket] = null;\n\n        while (current is not null)\n        {\n            if (current.Hashcode == hashcode && key.Equals(current.Key))\n            {\n                // found Entry - so we remove it from linked list\n                previous.Next = current.Next;       \n                return;\n            }\n            previous = current;\n            current = current.Next;\n        }\n        return;\n    }\n\n    /// <summary>\n    /// returns Value stored at key or nullvalue if not found.\n    /// </summary>\n    public V? GetValue(K key)\n    {\n        var entry = FindEntry(key);\n        if (entry is null) return default(V);\n        return entry.Value;\n    }\n\n    /// <summary>\n    /// if size reaches a certain loadfactor we reallocate with 2 times the capacity (this is slow/expensive)\n    /// </summary>\n    private void ReallocIfNeed()\n    {\n        const double LOADFACTOR = 0.75;\n        const int GROWFACTOR = 2;\n        if (Count < Capacity * LOADFACTOR) return;\n\n        var newCapacity = Capacity * GROWFACTOR;\n        var oldEntries = this.entries;\n        this.entries = new Entry[newCapacity];\n        foreach (var e in oldEntries)\n        {\n            if (e is not null) \n            {\n                // copy roots\n                this.Add(e.Key, e.Value);\n                var next = e.Next;\n                // copy linked elements\n                while (next is not null)\n                {\n                    this.Add(next.Key, next.Value);\n                    next = next.Next;\n                }\n            }\n        }\n    }\n\n    private Entry? FindEntry(K key)\n    {\n        int hashcode = key.GetHashCode();\n        int targetBucket = (hashcode & int.MaxValue) % entries.Length;\n        Entry? target = entries[targetBucket];\n        if (target is null) return null;\n        while (target is not null)\n        {\n            if (target.Hashcode == hashcode && key.Equals(target.Key)) return target;\n            target = target.Next;\n        }\n        return null;\n    }\n\n    // Inexer for our HashMap. Ex: \'var xyu = ourMap["someKey"]\'\n    public V? this[K key]\n    {\n        get => GetValue(key);\n        set{ Add(key, value!); }\n    }\n\n    IEnumerator IEnumerable.GetEnumerator() => this.GetEnumerator();\n    \n    public IEnumerator<KeyValuePair<K, V>> GetEnumerator()\n    {\n        var version = this.version;\n        foreach(var entry in entries)\n        {\n            var current = entry;\n            while (current is not null)\n            {\n                if (this.version != version) throw new InvalidOperationException("Collection modified.");\n                yield return new KeyValuePair<K, V>(current.Key, current.Value);\n                current = current.Next;\n            }\n        }\n    }\n}\n')))}h.isMDXComponent=!0}}]);